[`< Back`](./)

---

# StatefulExecutorBase

Namespace: LLama

The base class for stateful LLama executors.

```csharp
public abstract class StatefulExecutorBase : LLama.Abstractions.ILLamaExecutor
```

Inheritance [Object](https://docs.microsoft.com/en-us/dotnet/api/system.object) â†’ [StatefulExecutorBase](./llama.statefulexecutorbase.md)<br>
Implements [ILLamaExecutor](./llama.abstractions.illamaexecutor.md)<br>
Attributes [NullableContextAttribute](https://docs.microsoft.com/en-us/dotnet/api/system.runtime.compilerservices.nullablecontextattribute), [NullableAttribute](https://docs.microsoft.com/en-us/dotnet/api/system.runtime.compilerservices.nullableattribute)

## Fields

### **_logger**

The logger used by this executor.

```csharp
protected ILogger _logger;
```

### **_pastTokensCount**

The tokens that were already processed by the model.

```csharp
protected int _pastTokensCount;
```

### **_consumedTokensCount**

The tokens that were consumed by the model during the current inference.

```csharp
protected int _consumedTokensCount;
```

### **_n_session_consumed**



```csharp
protected int _n_session_consumed;
```

### **_n_matching_session_tokens**



```csharp
protected int _n_matching_session_tokens;
```

### **_pathSession**

The path of the session file.

```csharp
protected string _pathSession;
```

### **_embeds**

A container of the tokens to be processed and after processed.

```csharp
protected List<LLamaToken> _embeds;
```

### **_embed_inps**

A container for the tokens of input.

```csharp
protected List<LLamaToken> _embed_inps;
```

### **_session_tokens**



```csharp
protected List<LLamaToken> _session_tokens;
```

### **_last_n_tokens**

The last tokens generated by the model.

```csharp
protected FixedSizeQueue<LLamaToken> _last_n_tokens;
```

## Properties

### **Context**

The context used by the executor.

```csharp
public LLamaContext Context { get; }
```

#### Property Value

[LLamaContext](./llama.llamacontext.md)<br>

### **IsMultiModal**

```csharp
public bool IsMultiModal { get; }
```

#### Property Value

[Boolean](https://docs.microsoft.com/en-us/dotnet/api/system.boolean)<br>

### **ClipModel**

```csharp
public LLavaWeights ClipModel { get; }
```

#### Property Value

[LLavaWeights](./llama.llavaweights.md)<br>

### **Images**

```csharp
public List<Byte[]> Images { get; }
```

#### Property Value

[List&lt;Byte[]&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.list-1)<br>

## Constructors

### **StatefulExecutorBase(LLamaContext, ILogger)**



```csharp
protected StatefulExecutorBase(LLamaContext context, ILogger logger)
```

#### Parameters

`context` [LLamaContext](./llama.llamacontext.md)<br>

`logger` ILogger<br>

### **StatefulExecutorBase(LLamaContext, LLavaWeights, ILogger)**



```csharp
public StatefulExecutorBase(LLamaContext context, LLavaWeights lLavaWeights, ILogger logger)
```

#### Parameters

`context` [LLamaContext](./llama.llamacontext.md)<br>

`lLavaWeights` [LLavaWeights](./llama.llavaweights.md)<br>

`logger` ILogger<br>

## Methods

### **WithSessionFile(String)**

This API is currently not verified.

```csharp
public StatefulExecutorBase WithSessionFile(string filename)
```

#### Parameters

`filename` [String](https://docs.microsoft.com/en-us/dotnet/api/system.string)<br>

#### Returns

[StatefulExecutorBase](./llama.statefulexecutorbase.md)<br>

#### Exceptions

[ArgumentNullException](https://docs.microsoft.com/en-us/dotnet/api/system.argumentnullexception)<br>

[RuntimeError](./llama.exceptions.runtimeerror.md)<br>

### **SaveSessionFile(String)**

This API has not been verified currently.

```csharp
public void SaveSessionFile(string filename)
```

#### Parameters

`filename` [String](https://docs.microsoft.com/en-us/dotnet/api/system.string)<br>

### **HandleRunOutOfContext(Int32)**

After running out of the context, take some tokens from the original prompt and recompute the logits in batches.

```csharp
protected void HandleRunOutOfContext(int tokensToKeep)
```

#### Parameters

`tokensToKeep` [Int32](https://docs.microsoft.com/en-us/dotnet/api/system.int32)<br>

### **TryReuseMatchingPrefix()**

Try to reuse the matching prefix from the session file.

```csharp
protected void TryReuseMatchingPrefix()
```

### **GetLoopCondition(InferStateArgs)**

Decide whether to continue the loop.

```csharp
protected abstract Task<bool> GetLoopCondition(InferStateArgs args)
```

#### Parameters

`args` [InferStateArgs](./llama.statefulexecutorbase.inferstateargs.md)<br>

#### Returns

[Task&lt;Boolean&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task-1)<br>

### **PreprocessInputs(String, InferStateArgs)**

Preprocess the inputs before the inference.

```csharp
protected abstract Task PreprocessInputs(string text, InferStateArgs args)
```

#### Parameters

`text` [String](https://docs.microsoft.com/en-us/dotnet/api/system.string)<br>

`args` [InferStateArgs](./llama.statefulexecutorbase.inferstateargs.md)<br>

#### Returns

[Task](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task)<br>

### **PostProcess(IInferenceParams, InferStateArgs)**

Do some post processing after the inference.

```csharp
protected abstract Task<ValueTuple<bool, IReadOnlyList<string>>> PostProcess(IInferenceParams inferenceParams, InferStateArgs args)
```

#### Parameters

`inferenceParams` [IInferenceParams](./llama.abstractions.iinferenceparams.md)<br>

`args` [InferStateArgs](./llama.statefulexecutorbase.inferstateargs.md)<br>

#### Returns

[Task&lt;ValueTuple&lt;Boolean, IReadOnlyList&lt;String&gt;&gt;&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task-1)<br>

### **InferInternal(IInferenceParams, InferStateArgs)**

The core inference logic.

```csharp
protected abstract Task InferInternal(IInferenceParams inferenceParams, InferStateArgs args)
```

#### Parameters

`inferenceParams` [IInferenceParams](./llama.abstractions.iinferenceparams.md)<br>

`args` [InferStateArgs](./llama.statefulexecutorbase.inferstateargs.md)<br>

#### Returns

[Task](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task)<br>

### **SaveState(String)**

Save the current state to a file.

```csharp
public abstract Task SaveState(string filename)
```

#### Parameters

`filename` [String](https://docs.microsoft.com/en-us/dotnet/api/system.string)<br>

#### Returns

[Task](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task)<br>

### **GetStateData()**

Get the current state data.

```csharp
public abstract ExecutorBaseState GetStateData()
```

#### Returns

[ExecutorBaseState](./llama.statefulexecutorbase.executorbasestate.md)<br>

### **LoadState(ExecutorBaseState)**

Load the state from data.

```csharp
public abstract Task LoadState(ExecutorBaseState data)
```

#### Parameters

`data` [ExecutorBaseState](./llama.statefulexecutorbase.executorbasestate.md)<br>

#### Returns

[Task](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task)<br>

### **LoadState(String)**

Load the state from a file.

```csharp
public abstract Task LoadState(string filename)
```

#### Parameters

`filename` [String](https://docs.microsoft.com/en-us/dotnet/api/system.string)<br>

#### Returns

[Task](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task)<br>

### **InferAsync(String, IInferenceParams, CancellationToken)**

Execute the inference.

```csharp
public IAsyncEnumerable<string> InferAsync(string text, IInferenceParams inferenceParams, CancellationToken cancellationToken)
```

#### Parameters

`text` [String](https://docs.microsoft.com/en-us/dotnet/api/system.string)<br>
The prompt. If null, generation will continue where it left off previously.

`inferenceParams` [IInferenceParams](./llama.abstractions.iinferenceparams.md)<br>

`cancellationToken` [CancellationToken](https://docs.microsoft.com/en-us/dotnet/api/system.threading.cancellationtoken)<br>

#### Returns

[IAsyncEnumerable&lt;String&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.iasyncenumerable-1)<br>

### **PrefillPromptAsync(String)**

Asynchronously runs a prompt through the model to compute KV cache without generating any new tokens.
 It could reduce the latency of the first time response if the first input from the user is not immediate.

```csharp
public Task PrefillPromptAsync(string prompt)
```

#### Parameters

`prompt` [String](https://docs.microsoft.com/en-us/dotnet/api/system.string)<br>
Prompt to process

#### Returns

[Task](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task)<br>

---

[`< Back`](./)
